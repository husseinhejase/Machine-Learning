{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression\n",
    "\n",
    "- Implement a logistic regression model using a neural network mindset.\n",
    "- Code includes computing forward and backward propagation, gradients, and updating model parameters.\n",
    "\n",
    "*Pseudocode of the algorithm*:\n",
    "\n",
    "Forward step:\n",
    "$$Z = w^{T}X + b$$\n",
    "$$A = \\sigma(Z)$$\n",
    "\n",
    "Backward step:\n",
    "$$dZ = A - Y$$\n",
    "$$dw = \\frac{1}{m} XdZ^{T}$$\n",
    "$$db = \\frac{1}{m} \\sum^{m}_{i=1}{dZ^{(i)}}$$\n",
    "\n",
    "Cost function:\n",
    "$$J(w,b) = -\\frac{1}{m}\\sum_{i=1}^{m}(y^{(i)}log(a^{(i)}) + (1-y^{(i)})log(1-a^{(i)}))$$\n",
    "Update weights:\n",
    "$$w := w - \\alpha dw$$\n",
    "$$b := b - \\alpha db$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from lr_utils import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize(nx):\n",
    "    \"\"\"Initialize the parameters of the logistic regression model\"\"\"\n",
    "    w = np.zeros((nx, 1))\n",
    "    b = 0\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    \"\"\"Compute the sigmoid function\"\"\"\n",
    "    return 1 / (1+np.exp(-Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward(w, X, b):\n",
    "    \"\"\"Forward propagation\"\"\"\n",
    "    Z = np.dot(w.T, X) + b\n",
    "    A = sigmoid(Z)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backward(A, Y, X, m):\n",
    "    \"\"\"Backward propagation\"\"\"\n",
    "    dZ = A - Y\n",
    "    dw = np.dot(X, dZ.T) / m\n",
    "    db = np.sum(dZ) / m\n",
    "    return dw, db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost(A, Y, m):\n",
    "    \"\"\"Calculate the cost function across training examples\"\"\"\n",
    "    J = -1/m * (np.dot(Y, np.log(A).T) + np.dot(1-Y, np.log(1-A).T))\n",
    "    J = np.squeeze(J)\n",
    "    J = np.round(J,5)\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_param(w, b, dw, db, alpha):\n",
    "    \"\"\"Update parameters w and b based on the derivatives computed using gradient descent\"\"\"\n",
    "    w = w - alpha * dw\n",
    "    b = b - alpha * db\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Load the data, standardize, and reshape images into an nx by m feature matrix\n",
    "    \"\"\"\n",
    "    trainX, trainY, testX, testY, classes = load_dataset()\n",
    "    trainX = trainX / 255\n",
    "    testX = testX / 255\n",
    "    trainX = trainX.reshape((trainX.shape[0],-1)).T\n",
    "    testX = testX.reshape((testX.shape[0],-1)).T\n",
    "    return trainX, trainY, testX, testY, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X, Y, nx, m, nepoch=2000, alpha=0.005, print_cost=True):\n",
    "    \"\"\"\n",
    "    Optimize w and b by running gradient descent\n",
    "    (1) Initialize weights\n",
    "    (2) Forward propagation\n",
    "    (3) Compute cost J\n",
    "    (4) Backward propagation\n",
    "    (5) Update weight and intercept params\n",
    "    \"\"\"\n",
    "    w, b = initialize(nx)\n",
    "    for i in range(1, nepoch+1):\n",
    "        A = forward(w, X, b)\n",
    "        J = cost(A, Y, m)\n",
    "        if print_cost==True and i%250==0:\n",
    "            print('Step ', i, ', cost=', J, sep='')\n",
    "        dw, db = backward(A, Y, X, m)\n",
    "        w, b = update_param(w, b, dw, db, alpha)\n",
    "    print()\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(X, w, b):\n",
    "    \"\"\"Predict on test data using the trained model\"\"\"\n",
    "    A = forward(w, X, b)\n",
    "    A = A>=0.5\n",
    "    A = A.astype(int)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    trainX, trainY, testX, testY, classes = load_data()\n",
    "    nx = trainX.shape[0]\n",
    "    m = trainX.shape[1]\n",
    "    print('Shape of the training data (nx, m): ', nx, m)\n",
    "    w, b = model(trainX, trainY, nx, m)\n",
    "    predY = predict(testX, w, b)\n",
    "    print('Test accuracy: ', round(np.sum(predY==testY)/testX.shape[1] * 100,2), '%', sep='')\n",
    "    predY = predict(trainX, w, b)\n",
    "    print('Training accuracy: ', round(np.sum(predY==trainY)/trainX.shape[1] * 100,2), '%', sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training data (nx, m):  12288 209\n",
      "Step 250, cost=0.425\n",
      "Step 500, cost=0.30353\n",
      "Step 750, cost=0.25136\n",
      "Step 1000, cost=0.21494\n",
      "Step 1250, cost=0.18777\n",
      "Step 1500, cost=0.1666\n",
      "Step 1750, cost=0.14961\n",
      "Step 2000, cost=0.13566\n",
      "\n",
      "Test accuracy: 70.0%\n",
      "Training accuracy: 99.04%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
